# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

from abc import ABC,abstractmethod

class Runnable(ABC):

  @abstractmethod
  def invoke(input_data):
    pass

import random
class NakliLlm(Runnable):

  def __init__(self):
    print("LLM Created")

  def invoke(self,prompt):
    response_list = [
        "delhi is capital of india",
        "ipl is cricket league",
        "ai stands for artificial intelligence"
    ]
    return {"response" : random.choice(response_list)}


  def predict(self,prompt):
    response_list = [
        "delhi is capital of india",
        "ipl is cricket league",
        "ai stands for artificial intelligence"
    ]
    return {"response" : random.choice(response_list)}

class NakliPromptTemplate(Runnable) :

  def __init__(self , template , input_varibles ):
    self.template = template
    self.input_varibles = input_varibles

  def invoke(self , input_dict):
    return self.template.format(**input_dict)

  def format(self , input_dict):
    return self.template.format(**input_dict)

class NakliStrOutputParser(Runnable):
    def __init__(self):
      pass

    def invoke(self,input_data):
      return input_data['response']

template = NakliPromptTemplate(
    template = "Write a {length} poem about {topic}",
    input_varibles=['length' , 'topic']
)

parser = NakliStrOutputParser()

llm = NakliLlm()

class RunnableConnector(Runnable):
  def __init__(self,runnable_list):
    self.runnable_list=runnable_list

  def invoke(self,input_data):
    for runnable in self.runnable_list:
      input_data=runnable.invoke(input_data)
    return input_data

chain = RunnableConnector([template,llm,parser])

chain.invoke({
    'length':'short','topic':'india'
})

